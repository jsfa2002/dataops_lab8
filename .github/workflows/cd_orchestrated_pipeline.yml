name: CD - Orchestrated Data Pipeline
on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
  schedule:
    - cron: '0 6 * * *' # Ejecutar diariamente a las 6 AM UTC
jobs:
  execute-pipeline:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'staging' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Download source data
        run: |
          mkdir -p data/raw
          python scripts/download_sample_data.py
      - name: Execute orchestrated pipeline
        run: |
          mkdir -p logs
          python src/orchestrator.py
          echo "Pipeline execution completed"
      - name: Upload execution artifacts
        uses: actions/upload-artifact@v3
        with:
          name: pipeline-outputs-${{ github.run_id }}
          path: |
            data/outputs/
            logs/
          retention-days: 7
      - name: Generate execution report
        if: always()
        run: |
          python scripts/generate_execution_report.py
